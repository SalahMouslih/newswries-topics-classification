{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example is a list of integers (word indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the network will output a probability distribution over the 46\n",
    "different output classes—for every input sample, the network will produce a 46-\n",
    "dimensional output vector, where output[i] is the probability that the sample\n",
    "belongs to class i. The 46 scores will sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best loss function to use in this case is categorical_crossentropy. It measures\n",
    "the distance between two probability distributions: here, between the probability distribution output by the network and the true distribution of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s set apart 1,000 samples in the training data to use as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 2.7635 - accuracy: 0.4618 - val_loss: 1.8164 - val_accuracy: 0.6520\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4779 - accuracy: 0.7093 - val_loss: 1.3440 - val_accuracy: 0.7180\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0892 - accuracy: 0.7699 - val_loss: 1.1786 - val_accuracy: 0.7390\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8529 - accuracy: 0.8239 - val_loss: 1.0670 - val_accuracy: 0.7800\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6787 - accuracy: 0.8636 - val_loss: 0.9908 - val_accuracy: 0.8020\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.5432 - accuracy: 0.8896 - val_loss: 0.9549 - val_accuracy: 0.8050\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4365 - accuracy: 0.9126 - val_loss: 0.9256 - val_accuracy: 0.8170\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3533 - accuracy: 0.9268 - val_loss: 0.9227 - val_accuracy: 0.8110\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2965 - accuracy: 0.9361 - val_loss: 0.9415 - val_accuracy: 0.8140\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2496 - accuracy: 0.9440 - val_loss: 0.9277 - val_accuracy: 0.8170\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2142 - accuracy: 0.9489 - val_loss: 0.9368 - val_accuracy: 0.8170\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1888 - accuracy: 0.9506 - val_loss: 0.9653 - val_accuracy: 0.8150\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1687 - accuracy: 0.9533 - val_loss: 0.9742 - val_accuracy: 0.8160\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1560 - accuracy: 0.9551 - val_loss: 0.9759 - val_accuracy: 0.8140\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1429 - accuracy: 0.9534 - val_loss: 1.0503 - val_accuracy: 0.7990\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1337 - accuracy: 0.9580 - val_loss: 1.0436 - val_accuracy: 0.8010\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1227 - accuracy: 0.9585 - val_loss: 1.0787 - val_accuracy: 0.7960\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1261 - accuracy: 0.9569 - val_loss: 1.1107 - val_accuracy: 0.7940\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1148 - accuracy: 0.9568 - val_loss: 1.0447 - val_accuracy: 0.8110\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1140 - accuracy: 0.9585 - val_loss: 1.1641 - val_accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network begins to overfit after nine epochs. Let’s train a new network from\n",
    "scratch for nine epochs and then evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 2.6587 - accuracy: 0.5168 - val_loss: 1.7397 - val_accuracy: 0.6330\n",
      "Epoch 2/9\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4225 - accuracy: 0.6997 - val_loss: 1.3320 - val_accuracy: 0.7110\n",
      "Epoch 3/9\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0601 - accuracy: 0.7725 - val_loss: 1.1559 - val_accuracy: 0.7530\n",
      "Epoch 4/9\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8416 - accuracy: 0.8201 - val_loss: 1.0720 - val_accuracy: 0.7730\n",
      "Epoch 5/9\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6746 - accuracy: 0.8577 - val_loss: 1.0543 - val_accuracy: 0.7680\n",
      "Epoch 6/9\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5376 - accuracy: 0.8861 - val_loss: 0.9541 - val_accuracy: 0.8060\n",
      "Epoch 7/9\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4341 - accuracy: 0.9107 - val_loss: 0.9490 - val_accuracy: 0.8060\n",
      "Epoch 8/9\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3547 - accuracy: 0.9263 - val_loss: 0.9230 - val_accuracy: 0.8080\n",
      "Epoch 9/9\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2912 - accuracy: 0.9386 - val_loss: 0.9352 - val_accuracy: 0.8190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1125f2940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=9,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.7845\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another\n",
    "way to encode the labels would be to cast them as\n",
    "an integer tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this approach would change the choice of the loss function. The categorical_crossentropy, expects the labels to follow\n",
    "a categorical encoding. With integer labels, we should use sparse_categorical_\n",
    "crossentropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model with an information bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.8877 - accuracy: 0.3467 - val_loss: 2.3198 - val_accuracy: 0.3680\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 2.0324 - accuracy: 0.3886 - val_loss: 1.8429 - val_accuracy: 0.4040\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6277 - accuracy: 0.5779 - val_loss: 1.6025 - val_accuracy: 0.6010\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.4308 - accuracy: 0.6198 - val_loss: 1.5293 - val_accuracy: 0.6020\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.3102 - accuracy: 0.6336 - val_loss: 1.4874 - val_accuracy: 0.6190\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.2136 - accuracy: 0.6584 - val_loss: 1.4683 - val_accuracy: 0.6190\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.1371 - accuracy: 0.6850 - val_loss: 1.4600 - val_accuracy: 0.6370\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.0712 - accuracy: 0.7022 - val_loss: 1.5081 - val_accuracy: 0.6420\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.0126 - accuracy: 0.7176 - val_loss: 1.5137 - val_accuracy: 0.6480\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.9604 - accuracy: 0.7293 - val_loss: 1.5721 - val_accuracy: 0.6520\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.9145 - accuracy: 0.7409 - val_loss: 1.5851 - val_accuracy: 0.6590\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.8765 - accuracy: 0.7543 - val_loss: 1.5884 - val_accuracy: 0.6620\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8404 - accuracy: 0.7667 - val_loss: 1.6788 - val_accuracy: 0.6620\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.8086 - accuracy: 0.7750 - val_loss: 1.7136 - val_accuracy: 0.6680\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.7799 - accuracy: 0.7839 - val_loss: 1.7845 - val_accuracy: 0.6660\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.7538 - accuracy: 0.7905 - val_loss: 1.8282 - val_accuracy: 0.6650\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7323 - accuracy: 0.7923 - val_loss: 1.8750 - val_accuracy: 0.6660\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7133 - accuracy: 0.7957 - val_loss: 1.9123 - val_accuracy: 0.6600\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.6973 - accuracy: 0.7963 - val_loss: 1.9691 - val_accuracy: 0.6590\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.6818 - accuracy: 0.8001 - val_loss: 2.0799 - val_accuracy: 0.6610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb5d151f98>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This drop\n",
    "is mostly due to the fact that we’re trying to compress a lot of information (enough\n",
    "information to recover the separation hyperplanes of 46 classes) into an intermediate\n",
    "space that is too low-dimensional. One solution is to add larger layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7093 - accuracy: 0.6424 - val_loss: 1.2015 - val_accuracy: 0.7380\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.9187 - accuracy: 0.7985 - val_loss: 1.0399 - val_accuracy: 0.7760\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5987 - accuracy: 0.8707 - val_loss: 0.9052 - val_accuracy: 0.8100\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.3978 - accuracy: 0.9098 - val_loss: 0.8788 - val_accuracy: 0.8130\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.2860 - accuracy: 0.9347 - val_loss: 1.0712 - val_accuracy: 0.7760\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.2282 - accuracy: 0.9437 - val_loss: 0.9264 - val_accuracy: 0.8270\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1882 - accuracy: 0.9505 - val_loss: 0.9449 - val_accuracy: 0.8220\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.1703 - accuracy: 0.9525 - val_loss: 1.0221 - val_accuracy: 0.8030\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1553 - accuracy: 0.9540 - val_loss: 1.0296 - val_accuracy: 0.8150\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1420 - accuracy: 0.9557 - val_loss: 1.0879 - val_accuracy: 0.8040\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1368 - accuracy: 0.9549 - val_loss: 1.0451 - val_accuracy: 0.8090\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1306 - accuracy: 0.9553 - val_loss: 1.1336 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1244 - accuracy: 0.9546 - val_loss: 1.1037 - val_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1199 - accuracy: 0.9564 - val_loss: 1.1041 - val_accuracy: 0.8020\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1135 - accuracy: 0.9546 - val_loss: 1.1962 - val_accuracy: 0.7960\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1110 - accuracy: 0.9554 - val_loss: 1.2213 - val_accuracy: 0.7920\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1061 - accuracy: 0.9579 - val_loss: 1.1894 - val_accuracy: 0.8010\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.1034 - accuracy: 0.9562 - val_loss: 1.2205 - val_accuracy: 0.8030\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0992 - accuracy: 0.9565 - val_loss: 1.3468 - val_accuracy: 0.7840\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.0957 - accuracy: 0.9587 - val_loss: 1.3948 - val_accuracy: 0.7820\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history2 = model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7379999756813049,\n",
       " 0.7760000228881836,\n",
       " 0.8100000023841858,\n",
       " 0.8130000233650208,\n",
       " 0.7760000228881836,\n",
       " 0.8270000219345093,\n",
       " 0.8220000267028809,\n",
       " 0.8029999732971191,\n",
       " 0.8149999976158142,\n",
       " 0.8040000200271606,\n",
       " 0.8090000152587891,\n",
       " 0.800000011920929,\n",
       " 0.8040000200271606,\n",
       " 0.8019999861717224,\n",
       " 0.7960000038146973,\n",
       " 0.7919999957084656,\n",
       " 0.8009999990463257,\n",
       " 0.8029999732971191,\n",
       " 0.7839999794960022,\n",
       " 0.7820000052452087]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
